import numpy as np
import pandas as pd 
from keras.preprocessing.image import ImageDataGenerator, load_img
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import random
import os
#print(os.listdir("C:/Users/Froylan Jimenez/Documents/Tesis/Datos_nuevos/train"))
FAST_RUN = False
#Original 128
IMAGE_WIDTH=150
IMAGE_HEIGHT=150
IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)
IMAGE_CHANNELS=3
filenames = os.listdir("C:/Users/Froylan Jimenez/Documents/Tesis/Datos_nuevos/train")
categories = []
for filename in filenames:
    category = filename.split('-')[0]
    if category == 'health':
        categories.append(1)
    elif category == 'leaf':
        categories.append(2)
    else:
        categories.append(0)

df = pd.DataFrame({
    'filename': filenames,
    'category': categories
})
#Model 
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization

model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))  
model.add(Dropout(0.25)) #Dropout(0.25)

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.4))

model.add(Conv2D(128, (3, 3), activation='relu')) #activation="relu"
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
model.add(Dense(3, activation='softmax')) # 2 because we have cat and dog classes

model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])

model.summary()
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
earlystop = EarlyStopping(patience=10)
learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', #val_acc
                                            patience=2, 
                                            verbose=1, 
                                            factor=0.5, 
                                            min_lr=0.0001)
callbacks = [earlystop, learning_rate_reduction]
train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42) #test_size=0.20
train_df = train_df.reset_index(drop=True)
validate_df = validate_df.reset_index(drop=True)                                            
total_train = train_df.shape[0]
total_validate = validate_df.shape[0]
batch_size=15
train_datagen = ImageDataGenerator(
    rotation_range=2,#original 15
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.1, #original 0.2
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)

train_generator = train_datagen.flow_from_dataframe(
    train_df, 
    "C:/Users/Froylan Jimenez/Documents/Tesis/Datos_nuevos/train", 
    x_col='filename',
    y_col='category',
    target_size=IMAGE_SIZE,
    class_mode='categorical',
    batch_size=batch_size
)
validation_datagen = ImageDataGenerator(rescale=1./255)
validation_generator = validation_datagen.flow_from_dataframe(
    validate_df, 
    "C:/Users/Froylan Jimenez/Documents/Tesis/Datos_nuevos/train", 
    x_col='filename',
    y_col='category',
    target_size=IMAGE_SIZE,
    class_mode='categorical',
    batch_size=batch_size
)
#Transfer learning
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Dropout
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import regularizers
vgg_model=VGG16(include_top=False, input_shape=(150,150,3))
for layer in vgg_model.layers:
        layer.trainable=False
x = vgg_model.output
#add flatten layer so we can add the fully connected layer later
#This is using the Keras functional API but Sequential API works #just as well
x = Flatten()(x)
x = Dense(256, activation='relu')(x) #64
x = Dropout(0.05)(x)
x = Dense(3, activation='softmax')(x)
#create the new model
model = Model(input=vgg_model.input, output=x)
print(model.summary())
model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy']) #optimizer="rmsprop"
epochs=3 if FAST_RUN else 20
history = model.fit_generator(
    train_generator, 
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=total_validate//batch_size,
    steps_per_epoch=total_train//batch_size,
    callbacks=callbacks
)
